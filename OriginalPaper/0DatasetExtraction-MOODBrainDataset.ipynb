{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip extraction\n",
    "This notebook extracts volumes from zip provided in MOOD Challenge. Resizes volumes to (256,160,160) and saves them as namedtuples as consumed by the dataloaders in 1. Latent Spatial Reconstructions - MOOD Brain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "import nibabel as nib\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(case_id, vol, tgt_dir):\n",
    "    \n",
    "    target_file = os.path.join(tgt_dir, case_id + \".nt\")\n",
    "    \n",
    "    x_tmp = [img_extended(vol, None, None, None, None, case_id)]\n",
    "    pickle.dump(x_tmp, open(target_file, 'wb'))\n",
    "\n",
    "img_extended = namedtuple('img_extended',('img','seg','k','t','coord','cid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the processed volumes are saved\n",
    "tgt_dir = ''\n",
    "\n",
    "# Location of mood challenge brain zip\n",
    "src_zip = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(src_zip) as myzip:\n",
    "\n",
    "    for i,file_name in enumerate(myzip.namelist()):\n",
    "        if file_name.split('.')[-1] == 'gz':\n",
    "            file = myzip.read(file_name)\n",
    "            f = open('./tmp_file.nii.gz','wb')\n",
    "            f.write(file)\n",
    "            \n",
    "            vol = nib.load('./tmp_file.nii.gz')\n",
    "            vol = np.asarray(vol.get_fdata())\n",
    "            vol = resize(vol, (160, 160, 256))\n",
    "            vol = vol.transpose((2,1,0))\n",
    "            vol = vol[:, ::-1, :]\n",
    "            vol = (vol * 255).astype('uint8')\n",
    "            case_id = file_name.split('.')[0].split('/')[1]\n",
    "            \n",
    "            save_file(case_id, vol, tgt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 volumes are moved manually from training directory to a different directory as a holdout dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
