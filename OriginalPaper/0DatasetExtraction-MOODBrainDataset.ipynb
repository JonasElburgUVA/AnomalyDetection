{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip extraction\n",
    "This notebook extracts volumes from zip provided in MOOD Challenge. Resizes volumes to (256,160,160) and saves them as namedtuples as consumed by the dataloaders in 1. Latent Spatial Reconstructions - MOOD Brain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "import nibabel as nib\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(case_id, vol, tgt_dir):\n",
    "    \n",
    "    target_file = os.path.join(tgt_dir, case_id + \".nt\")\n",
    "    \n",
    "    x_tmp = [img_extended(vol, None, None, None, None, case_id)]\n",
    "    pickle.dump(x_tmp, open(target_file, 'wb'))\n",
    "\n",
    "img_extended = namedtuple('img_extended',('img','seg','k','t','coord','cid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the processed volumes are saved\n",
    "tgt_dir = ''\n",
    "\n",
    "# Location of mood challenge brain zip\n",
    "src_zip = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(src_zip) as myzip:\n",
    "\n",
    "    for i,file_name in enumerate(myzip.namelist()):\n",
    "        if file_name.split('.')[-1] == 'gz':\n",
    "            file = myzip.read(file_name)\n",
    "            f = open('./tmp_file.nii.gz','wb')\n",
    "            f.write(file)\n",
    "            \n",
    "            vol = nib.load('./tmp_file.nii.gz')\n",
    "            vol = np.asarray(vol.get_fdata())\n",
    "            vol = resize(vol, (160, 160, 256))\n",
    "            vol = vol.transpose((2,1,0))\n",
    "            vol = vol[:, ::-1, :]\n",
    "            vol = (vol * 255).astype('uint8')\n",
    "            case_id = file_name.split('.')[0].split('/')[1]\n",
    "            \n",
    "            save_file(case_id, vol, tgt_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 volumes are moved manually from training directory to a different directory as a holdout dataset. The following code normalizes the MRI images using full-volume statistics and saves them to `preprocessed_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_sample = namedtuple('mri_sample', ('img', 'seg', 'k', 't', 'coord', 'cid', 'empty_mask'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offline_preprocessing(img, slice_offset=20):\n",
    "    \"\"\"\n",
    "        Compute the mask of ignored slices and normalize\n",
    "        slices using full-volume statistics\n",
    "    \"\"\"\n",
    "    empty_mask = ~np.all(img == 0, axis=(1,2))\n",
    "\n",
    "    empty_mask[:slice_offset] = False\n",
    "    empty_mask[-slice_offset:] = False\n",
    "\n",
    "    statistics_mask = np.where(img > 0.05)\n",
    "    mu, std = img[statistics_mask].mean(), img[statistics_mask].std()\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    normalization_mask = np.where(img > 0.05)\n",
    "    img[normalization_mask] = (img[normalization_mask] - mu) / std\n",
    "\n",
    "    return img, empty_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Perform additiona preprocessing (currently done in the dataloader)\n",
    "slice_offset = 20\n",
    "filenames = glob.glob(\"brain_data/*.nt\")\n",
    "\n",
    "for file_path in filenames:\n",
    "    filename = file_path.split(\"/\")[-1]\n",
    "    item = pickle.load(open(file_path, \"rb\")).pop()\n",
    "\n",
    "    img, empty_mask = offline_preprocessing(item.img)\n",
    "\n",
    "    sample = mri_sample(\n",
    "        img,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        empty_mask\n",
    "    )\n",
    "\n",
    "    pickle.dump(sample, open(f\"preprocessed_data/{filename}\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf preprocessed_data.tar.gz preprocessed_data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
